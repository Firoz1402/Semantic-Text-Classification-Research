{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2399a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-19 23:57:38.883874: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-19 23:57:40.079673: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roronoa/.conda/envs/tf/lib/python3.7/site-packages/nvidia/cudnn/lib:/home/roronoa/.conda/envs/tf/lib/:\n",
      "2023-10-19 23:57:40.079778: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roronoa/.conda/envs/tf/lib/python3.7/site-packages/nvidia/cudnn/lib:/home/roronoa/.conda/envs/tf/lib/:\n",
      "2023-10-19 23:57:40.079789: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score,accuracy_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, Callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "635169ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/CleanedEcommerce.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "309ee729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Household</td>\n",
       "      <td>paper plane design frame wall hang motiv offic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Household</td>\n",
       "      <td>saf frame paint wood 30 inch x 10 inch special...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Household</td>\n",
       "      <td>saf textur modern art print frame paint synthe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Household</td>\n",
       "      <td>saf flower print frame paint synthet 13 5 inch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Household</td>\n",
       "      <td>incred gift india wooden happi birthday uniqu ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               desc\n",
       "0  Household  paper plane design frame wall hang motiv offic...\n",
       "1  Household  saf frame paint wood 30 inch x 10 inch special...\n",
       "2  Household  saf textur modern art print frame paint synthe...\n",
       "3  Household  saf flower print frame paint synthet 13 5 inch...\n",
       "4  Household  incred gift india wooden happi birthday uniqu ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98701213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27802 entries, 0 to 27801\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   27802 non-null  object\n",
      " 1   desc    27801 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 434.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4c37e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6774dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text - Input; Label = Output\n",
    "text = 'desc'\n",
    "label = 'label'\n",
    "num_classes = df[label].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a67fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[text].values\n",
    "y = df[label].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d0756db",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2763677",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a94e9086",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000  # You can adjust this based on your dataset\n",
    "max_seq_len = 300  # You can adjust this based on your dataset\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_seq_len)\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d58bc51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balancing the Distribution of labels\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_padded, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a13a0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33804, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26941d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 128, input_length=max_seq_len))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.03, patience=10, mode='max', restore_best_weights=True)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf92331c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "212/212 [==============================] - 20s 74ms/step - loss: 0.5207 - accuracy: 0.8297 - val_loss: 0.6060 - val_accuracy: 0.8110\n",
      "Epoch 2/50\n",
      "212/212 [==============================] - 12s 56ms/step - loss: 0.2846 - accuracy: 0.9287 - val_loss: 0.3008 - val_accuracy: 0.9218\n",
      "Epoch 3/50\n",
      "212/212 [==============================] - 12s 55ms/step - loss: 0.2504 - accuracy: 0.9370 - val_loss: 0.3388 - val_accuracy: 0.9117\n",
      "Epoch 4/50\n",
      "212/212 [==============================] - 11s 53ms/step - loss: 0.2349 - accuracy: 0.9384 - val_loss: 0.3713 - val_accuracy: 0.9046\n",
      "Epoch 5/50\n",
      "212/212 [==============================] - 12s 55ms/step - loss: 0.2107 - accuracy: 0.9470 - val_loss: 0.2873 - val_accuracy: 0.9238\n",
      "Epoch 6/50\n",
      "212/212 [==============================] - 12s 56ms/step - loss: 0.1916 - accuracy: 0.9536 - val_loss: 0.2440 - val_accuracy: 0.9284\n",
      "Epoch 7/50\n",
      "212/212 [==============================] - 11s 54ms/step - loss: 0.1773 - accuracy: 0.9566 - val_loss: 0.5666 - val_accuracy: 0.7570\n",
      "Epoch 8/50\n",
      "212/212 [==============================] - 12s 55ms/step - loss: 0.2005 - accuracy: 0.9468 - val_loss: 0.2378 - val_accuracy: 0.9368\n",
      "Epoch 9/50\n",
      "212/212 [==============================] - 12s 54ms/step - loss: 0.1944 - accuracy: 0.9504 - val_loss: 0.2110 - val_accuracy: 0.9376\n",
      "Epoch 10/50\n",
      "212/212 [==============================] - 12s 54ms/step - loss: 0.1693 - accuracy: 0.9563 - val_loss: 0.1906 - val_accuracy: 0.9487\n",
      "Epoch 11/50\n",
      "212/212 [==============================] - 12s 55ms/step - loss: 0.1721 - accuracy: 0.9560 - val_loss: 0.1557 - val_accuracy: 0.9590\n",
      "Epoch 12/50\n",
      "212/212 [==============================] - 12s 55ms/step - loss: 0.1526 - accuracy: 0.9624 - val_loss: 0.2068 - val_accuracy: 0.9326\n",
      "Epoch 13/50\n",
      "212/212 [==============================] - 12s 56ms/step - loss: 0.1412 - accuracy: 0.9656 - val_loss: 0.1644 - val_accuracy: 0.9580\n",
      "Epoch 14/50\n",
      "212/212 [==============================] - 12s 56ms/step - loss: 0.1332 - accuracy: 0.9683 - val_loss: 0.3069 - val_accuracy: 0.8929\n",
      "Epoch 15/50\n",
      "212/212 [==============================] - 12s 56ms/step - loss: 0.1303 - accuracy: 0.9681 - val_loss: 0.1470 - val_accuracy: 0.9608\n",
      "Epoch 16/50\n",
      "212/212 [==============================] - 12s 55ms/step - loss: 0.1304 - accuracy: 0.9677 - val_loss: 0.1333 - val_accuracy: 0.9604\n",
      "Epoch 17/50\n",
      "212/212 [==============================] - 12s 55ms/step - loss: 0.1171 - accuracy: 0.9715 - val_loss: 0.1159 - val_accuracy: 0.9703\n",
      "Epoch 18/50\n",
      "212/212 [==============================] - 12s 55ms/step - loss: 0.1225 - accuracy: 0.9703 - val_loss: 0.1539 - val_accuracy: 0.9533\n",
      "Epoch 19/50\n",
      "212/212 [==============================] - 12s 55ms/step - loss: 0.1154 - accuracy: 0.9725 - val_loss: 0.1351 - val_accuracy: 0.9635\n",
      "Epoch 20/50\n",
      "212/212 [==============================] - 12s 56ms/step - loss: 0.1146 - accuracy: 0.9712 - val_loss: 0.1089 - val_accuracy: 0.9729\n",
      "Epoch 21/50\n",
      "212/212 [==============================] - 12s 56ms/step - loss: 0.1094 - accuracy: 0.9727 - val_loss: 0.1375 - val_accuracy: 0.9592\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_resampled, y_train_resampled, epochs=50, batch_size=128, validation_split=0.2,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac15c07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 3s 12ms/step\n",
      "Accuracy: 0.9221\n",
      "F1 Score: 0.9222\n",
      "Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                 Books       0.93      0.92      0.92      1251\n",
      "Clothing & Accessories       0.95      0.96      0.96      1135\n",
      "           Electronics       0.87      0.93      0.90      1062\n",
      "             Household       0.93      0.90      0.92      2113\n",
      "\n",
      "              accuracy                           0.92      5561\n",
      "             macro avg       0.92      0.93      0.92      5561\n",
      "          weighted avg       0.92      0.92      0.92      5561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities for all classes for the test set\n",
    "y_pred_probabilities = model.predict(X_test_padded)\n",
    "\n",
    "# Choose the class with the highest probability as the predicted class\n",
    "y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
    "\n",
    "# Decode the actual labels to their original class names\n",
    "y_true_decoded = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "# Decode the predicted labels to their original class names\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true_decoded, y_pred_decoded)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_true_decoded, y_pred_decoded, average='weighted')\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_true_decoded, y_pred_decoded)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd52751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
