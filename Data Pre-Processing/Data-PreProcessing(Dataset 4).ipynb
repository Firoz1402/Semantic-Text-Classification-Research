{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28d7255d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 13:22:21.308068: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-10 13:22:22.015152: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roronoa/.conda/envs/tf/lib/python3.7/site-packages/nvidia/cudnn/lib:/home/roronoa/.conda/envs/tf/lib/:/home/roronoa/.conda/envs/tf/lib/python3.7/site-packages/nvidia/cudnn/lib:/home/roronoa/.conda/envs/tf/lib/:\n",
      "2023-10-10 13:22:22.015255: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roronoa/.conda/envs/tf/lib/python3.7/site-packages/nvidia/cudnn/lib:/home/roronoa/.conda/envs/tf/lib/:/home/roronoa/.conda/envs/tf/lib/python3.7/site-packages/nvidia/cudnn/lib:/home/roronoa/.conda/envs/tf/lib/:\n",
      "2023-10-10 13:22:22.015267: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import nlpaug.augmenter.word as naw\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c495b1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roronoa/.conda/envs/tf/lib/python3.7/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_data_file = '../Data/Genre Classification Dataset/train_data.txt'\n",
    "test_solution_file = '../Data/Genre Classification Dataset/test_data_solution.txt'\n",
    "\n",
    "# Load the train data\n",
    "train_df = pd.read_csv(train_data_file, delimiter=':::', names=['title', 'genre', 'desc'])\n",
    "\n",
    "# Load the test data solution\n",
    "test_solution_df = pd.read_csv(test_solution_file, delimiter=':::', names=['title', 'genre', 'desc'])\n",
    "\n",
    "# Merge the train data and test data solution based on the \"title\" column\n",
    "df = pd.concat([train_df, test_solution_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f5fe433",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df\n",
    "del test_solution_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e2f3b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='title', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f55c652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre    0\n",
       "desc     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60baef0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7a34f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(keep = \"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7347c367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The story of Coral Fusion Latina; Canada's first and only Latin American choir. Its members are amateur singers and all are immigrants to Canada, representing countries such as Brazil, Columbia, Spain, Chile, Mexico, Costa Rica, Venezuela, and Argentina. The documentary follows the progress of the choir shortly after its inception, and culminates in their debut concert in front of a Vancouver audience one year later. Rehearsals, for the members of Fusion Latina, provide an opportunity to socialize with fellow Latinos and let loose in a way not afforded in their daily lives within Canada's relatively reserved Anglo-Saxon society. Their rambunctious behaviour, however, tend to turn rehearsals into free-for-all's, which frustrates their Argentinean born-Canadian raised conductor no end as she endeavors to prepare them for their debut.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['desc'].iloc[23500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c83d60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " drama           27117\n",
       " documentary     26152\n",
       " comedy          14860\n",
       " short           10114\n",
       " horror           4406\n",
       " thriller         3179\n",
       " action           2626\n",
       " western          2061\n",
       " reality-tv       1763\n",
       " adventure        1548\n",
       " family           1546\n",
       " music            1437\n",
       " romance          1340\n",
       " sci-fi           1292\n",
       " adult            1179\n",
       " crime            1007\n",
       " animation         994\n",
       " sport             859\n",
       " talk-show         775\n",
       " fantasy           645\n",
       " mystery           636\n",
       " musical           548\n",
       " biography         529\n",
       " history           486\n",
       " game-show         387\n",
       " news              362\n",
       " war               264\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68b8e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "df['genre'] = encoder.fit_transform(df['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da530d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81c356d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upon Checking the dataset, There seems to be no sign of anomalies like html tags, urls, etc\n",
    "#For reassurance, we can run the code 1 time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "689919f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    # Define a regular expression pattern to match URLs\n",
    "    url_pattern = r'https?://\\S+|www\\.\\S+'\n",
    "    return re.sub(url_pattern, '', text)\n",
    "\n",
    "df['desc']= df['desc'].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1e9d3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roronoa/.conda/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Removing HTML tags from the whole dataset\n",
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "df['desc'] = df['desc'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff03d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there was no space after each full stop, NLTK sent_tokenize considered 2 sentences as 1\n",
    "def insert_space_after_full_stop(text):\n",
    "    return text.replace('.', '. ')\n",
    "df['desc'] = df['desc'].apply(insert_space_after_full_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59746ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Listening in to a conversation between his doc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>A brother and sister with a past incestuous re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>As the bus empty the students for their field ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>To help their unemployed father make end meet,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>The film's title refer not only to the un-reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genre                                               desc\n",
       "0      8  Listening in to a conversation between his doc...\n",
       "1     24  A brother and sister with a past incestuous re...\n",
       "2      1  As the bus empty the students for their field ...\n",
       "3      8  To help their unemployed father make end meet,...\n",
       "4      8  The film's title refer not only to the un-reco..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatization(text):\n",
    "    lm= WordNetLemmatizer()\n",
    "    text = ' '.join([lm.lemmatize(word, pos='v') for word in text.split()])\n",
    "    return text\n",
    "df['desc']= df['desc'].apply(lemmatization)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc3585de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dong-woo be release from prison after a short time follow his fail attempt to rob a watch shop. He decide to follow in his brother's footsteps and become a singer. His popularity soon eclipse his brother's, however, lead to unexpected jealousy and family problems\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[24]['desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12317855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying major transformation to text such as lowering text, removing stopwords, stemming, removing\n",
    "#punctuations\n",
    "\n",
    "ps = PorterStemmer();\n",
    "def text_transform(text):\n",
    "    text= text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    y=[]\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "    \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "        \n",
    "    \n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3121aff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['desc']=df['desc'].apply(text_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a071ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 108112 entries, 0 to 108413\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   genre   108112 non-null  int64 \n",
      " 1   desc    108112 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf5269fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'releas prison short time follow fail attempt rob watch shop decid follow brother footstep becom singer popular soon eclips brother howev lead unexpect jealousi famili problem'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[24]['desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a189137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../Data/Movie_Genre(Dataset1).csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40245830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
