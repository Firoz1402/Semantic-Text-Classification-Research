{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3611c665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 02:46:10.863285: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-22 02:46:11.495923: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roronoa/.conda/envs/tf/lib/python3.7/site-packages/nvidia/cudnn/lib:/home/roronoa/.conda/envs/tf/lib/:\n",
      "2023-09-22 02:46:11.496001: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roronoa/.conda/envs/tf/lib/python3.7/site-packages/nvidia/cudnn/lib:/home/roronoa/.conda/envs/tf/lib/:\n",
      "2023-09-22 02:46:11.496011: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1630e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/CleanedData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7faa71c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['transformed text'].astype(str).tolist()\n",
    "labels = df['subject'].astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84b0695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 1000  # Set your desired sequence length\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "y = tf.keras.utils.to_categorical(labels, num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "465bde78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "083f3c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_sequence_length),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1a8ce1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "432/432 [==============================] - 29s 65ms/step - loss: 1.0258 - accuracy: 0.6077 - val_loss: 0.6251 - val_accuracy: 0.7593 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "432/432 [==============================] - 19s 44ms/step - loss: 0.5044 - accuracy: 0.8062 - val_loss: 0.5578 - val_accuracy: 0.7738 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "432/432 [==============================] - 13s 30ms/step - loss: 0.3569 - accuracy: 0.8435 - val_loss: 0.6393 - val_accuracy: 0.7690 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "432/432 [==============================] - 12s 27ms/step - loss: 0.3032 - accuracy: 0.8594 - val_loss: 0.7366 - val_accuracy: 0.7719 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "432/432 [==============================] - 10s 23ms/step - loss: 0.2636 - accuracy: 0.8736 - val_loss: 0.8950 - val_accuracy: 0.7659 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "432/432 [==============================] - 10s 22ms/step - loss: 0.2358 - accuracy: 0.8874 - val_loss: 0.9262 - val_accuracy: 0.7197 - lr: 9.0484e-04\n",
      "Epoch 7/30\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.2100 - accuracy: 0.8990 - val_loss: 1.0289 - val_accuracy: 0.7251 - lr: 8.1873e-04\n"
     ]
    }
   ],
   "source": [
    "lr_schedule = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=30, batch_size=64, validation_split=0.2, \n",
    "    callbacks=[early_stopping, lr_schedule]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "303c260e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 2ms/step\n",
      "Test F1 Score: 0.7490039669400765\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate F1 score\n",
    "test_f1_score = f1_score(np.argmax(y_test, axis=1), predicted_labels, average='weighted')\n",
    "\n",
    "print(\"Test F1 Score:\", test_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3501dbff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
