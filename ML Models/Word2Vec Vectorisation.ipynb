{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea653ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-23 01:05:55.170969: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-23 01:05:56.290284: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roronoa/.conda/envs/tf/lib/python3.7/site-packages/nvidia/cudnn/lib:/home/roronoa/.conda/envs/tf/lib/:\n",
      "2023-09-23 01:05:56.290406: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roronoa/.conda/envs/tf/lib/python3.7/site-packages/nvidia/cudnn/lib:/home/roronoa/.conda/envs/tf/lib/:\n",
      "2023-09-23 01:05:56.290417: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-09-23 01:05:56.965184: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-23 01:05:57.025535: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-23 01:05:57.025816: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6a17821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e751c52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------------------------------] 1.4% 23.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=-------------------------------------------------] 3.8% 62.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================---------------------------------] 35.8% 595.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================--------------------------------] 37.7% 626.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "410684e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.save('../../vectos.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a82887ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "wv = KeyedVectors.load('../../vectos.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ba4a4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013214114"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(\"usa\", \"trump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cddeaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/CleanedData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7172c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stop_words = nlp.Defaults.stop_words\n",
    "punctuations = string.punctuation\n",
    "def sent_vec(sent):\n",
    "    vector_size = wv.vector_size\n",
    "    wv_res = np.zeros(vector_size)\n",
    "    # print(wv_res)\n",
    "    ctr = 1\n",
    "    for w in sent:\n",
    "        if w in wv:\n",
    "            ctr += 1\n",
    "            wv_res += wv[w]\n",
    "    wv_res = wv_res/ctr\n",
    "    return wv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce944fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "\n",
    "\n",
    "    # print(doc)\n",
    "    # print(type(doc))\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() for word in doc ]\n",
    "\n",
    "    # print(mytokens)\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d074d488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efdebee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['transformed text'].apply(spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4912cb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>transformed text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>donald trump wish american happi new year leav...</td>\n",
       "      <td>[donald, trump, wish, american, happi, new, ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hous intellig committe chairman devin nune go ...</td>\n",
       "      <td>[hous, intellig, committe, chairman, devin, nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>friday reveal former milwauke sheriff david cl...</td>\n",
       "      <td>[friday, reveal, milwauke, sheriff, david, cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>christma day donald trump announc would back w...</td>\n",
       "      <td>[christma, day, donald, trump, announc, work, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>pope franci use annual christma day messag reb...</td>\n",
       "      <td>[pope, franci, use, annual, christma, day, mes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43120</th>\n",
       "      <td>5</td>\n",
       "      <td>brussel reuter nato alli tuesday welcom presid...</td>\n",
       "      <td>[brussel, reuter, nato, alli, tuesday, welcom,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43121</th>\n",
       "      <td>5</td>\n",
       "      <td>london reuter lexisnexi provid legal regulator...</td>\n",
       "      <td>[london, reuter, lexisnexi, provid, legal, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43122</th>\n",
       "      <td>5</td>\n",
       "      <td>minsk reuter shadow disus factori minsk street...</td>\n",
       "      <td>[minsk, reuter, shadow, disus, factori, minsk,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43123</th>\n",
       "      <td>5</td>\n",
       "      <td>moscow reuter vatican secretari state cardin p...</td>\n",
       "      <td>[moscow, reuter, vatican, secretari, state, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43124</th>\n",
       "      <td>5</td>\n",
       "      <td>jakarta reuter indonesia buy 11 sukhoi fighter...</td>\n",
       "      <td>[jakarta, reuter, indonesia, buy, 11, sukhoi, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43125 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject                                   transformed text  \\\n",
       "0            1  donald trump wish american happi new year leav...   \n",
       "1            1  hous intellig committe chairman devin nune go ...   \n",
       "2            1  friday reveal former milwauke sheriff david cl...   \n",
       "3            1  christma day donald trump announc would back w...   \n",
       "4            1  pope franci use annual christma day messag reb...   \n",
       "...        ...                                                ...   \n",
       "43120        5  brussel reuter nato alli tuesday welcom presid...   \n",
       "43121        5  london reuter lexisnexi provid legal regulator...   \n",
       "43122        5  minsk reuter shadow disus factori minsk street...   \n",
       "43123        5  moscow reuter vatican secretari state cardin p...   \n",
       "43124        5  jakarta reuter indonesia buy 11 sukhoi fighter...   \n",
       "\n",
       "                                                  tokens  \n",
       "0      [donald, trump, wish, american, happi, new, ye...  \n",
       "1      [hous, intellig, committe, chairman, devin, nu...  \n",
       "2      [friday, reveal, milwauke, sheriff, david, cla...  \n",
       "3      [christma, day, donald, trump, announc, work, ...  \n",
       "4      [pope, franci, use, annual, christma, day, mes...  \n",
       "...                                                  ...  \n",
       "43120  [brussel, reuter, nato, alli, tuesday, welcom,...  \n",
       "43121  [london, reuter, lexisnexi, provid, legal, reg...  \n",
       "43122  [minsk, reuter, shadow, disus, factori, minsk,...  \n",
       "43123  [moscow, reuter, vatican, secretari, state, ca...  \n",
       "43124  [jakarta, reuter, indonesia, buy, 11, sukhoi, ...  \n",
       "\n",
       "[43125 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6476d427",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vec'] = df['tokens'].apply(sent_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ce18433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>transformed text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>donald trump wish american happi new year leav...</td>\n",
       "      <td>[donald, trump, wish, american, happi, new, ye...</td>\n",
       "      <td>[0.017181913731461863, 0.054051674018471926, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hous intellig committe chairman devin nune go ...</td>\n",
       "      <td>[hous, intellig, committe, chairman, devin, nu...</td>\n",
       "      <td>[-0.03612939579280343, 0.031220203309547244, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>friday reveal former milwauke sheriff david cl...</td>\n",
       "      <td>[friday, reveal, milwauke, sheriff, david, cla...</td>\n",
       "      <td>[0.008666840358753109, 0.026369996331817476, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>christma day donald trump announc would back w...</td>\n",
       "      <td>[christma, day, donald, trump, announc, work, ...</td>\n",
       "      <td>[-0.01427909655448718, 0.009708936397845928, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>pope franci use annual christma day messag reb...</td>\n",
       "      <td>[pope, franci, use, annual, christma, day, mes...</td>\n",
       "      <td>[0.025674139703070368, 0.05516485067514273, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43120</th>\n",
       "      <td>5</td>\n",
       "      <td>brussel reuter nato alli tuesday welcom presid...</td>\n",
       "      <td>[brussel, reuter, nato, alli, tuesday, welcom,...</td>\n",
       "      <td>[-0.027124954482256356, 0.054149837817175916, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43121</th>\n",
       "      <td>5</td>\n",
       "      <td>london reuter lexisnexi provid legal regulator...</td>\n",
       "      <td>[london, reuter, lexisnexi, provid, legal, reg...</td>\n",
       "      <td>[-0.0667880189185049, 0.05341683182061887, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43122</th>\n",
       "      <td>5</td>\n",
       "      <td>minsk reuter shadow disus factori minsk street...</td>\n",
       "      <td>[minsk, reuter, shadow, disus, factori, minsk,...</td>\n",
       "      <td>[0.017276571347163275, 0.04812049865722656, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43123</th>\n",
       "      <td>5</td>\n",
       "      <td>moscow reuter vatican secretari state cardin p...</td>\n",
       "      <td>[moscow, reuter, vatican, secretari, state, ca...</td>\n",
       "      <td>[0.012695498582793445, 0.012704895763862424, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43124</th>\n",
       "      <td>5</td>\n",
       "      <td>jakarta reuter indonesia buy 11 sukhoi fighter...</td>\n",
       "      <td>[jakarta, reuter, indonesia, buy, 11, sukhoi, ...</td>\n",
       "      <td>[-0.022217792013417118, 0.03246771770974864, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43125 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject                                   transformed text  \\\n",
       "0            1  donald trump wish american happi new year leav...   \n",
       "1            1  hous intellig committe chairman devin nune go ...   \n",
       "2            1  friday reveal former milwauke sheriff david cl...   \n",
       "3            1  christma day donald trump announc would back w...   \n",
       "4            1  pope franci use annual christma day messag reb...   \n",
       "...        ...                                                ...   \n",
       "43120        5  brussel reuter nato alli tuesday welcom presid...   \n",
       "43121        5  london reuter lexisnexi provid legal regulator...   \n",
       "43122        5  minsk reuter shadow disus factori minsk street...   \n",
       "43123        5  moscow reuter vatican secretari state cardin p...   \n",
       "43124        5  jakarta reuter indonesia buy 11 sukhoi fighter...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      [donald, trump, wish, american, happi, new, ye...   \n",
       "1      [hous, intellig, committe, chairman, devin, nu...   \n",
       "2      [friday, reveal, milwauke, sheriff, david, cla...   \n",
       "3      [christma, day, donald, trump, announc, work, ...   \n",
       "4      [pope, franci, use, annual, christma, day, mes...   \n",
       "...                                                  ...   \n",
       "43120  [brussel, reuter, nato, alli, tuesday, welcom,...   \n",
       "43121  [london, reuter, lexisnexi, provid, legal, reg...   \n",
       "43122  [minsk, reuter, shadow, disus, factori, minsk,...   \n",
       "43123  [moscow, reuter, vatican, secretari, state, ca...   \n",
       "43124  [jakarta, reuter, indonesia, buy, 11, sukhoi, ...   \n",
       "\n",
       "                                                     vec  \n",
       "0      [0.017181913731461863, 0.054051674018471926, 0...  \n",
       "1      [-0.03612939579280343, 0.031220203309547244, 0...  \n",
       "2      [0.008666840358753109, 0.026369996331817476, 0...  \n",
       "3      [-0.01427909655448718, 0.009708936397845928, 0...  \n",
       "4      [0.025674139703070368, 0.05516485067514273, 0....  \n",
       "...                                                  ...  \n",
       "43120  [-0.027124954482256356, 0.054149837817175916, ...  \n",
       "43121  [-0.0667880189185049, 0.05341683182061887, -0....  \n",
       "43122  [0.017276571347163275, 0.04812049865722656, 0....  \n",
       "43123  [0.012695498582793445, 0.012704895763862424, 0...  \n",
       "43124  [-0.022217792013417118, 0.03246771770974864, -...  \n",
       "\n",
       "[43125 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7355e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['subject','vec']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8fcb8319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roronoa/.conda/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['vec'] = df['vec'].apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4920da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('word2vecData.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a62570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('word2vecData.csv', dtype={'word_vector_column': object})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b999502",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['vec'].to_list()\n",
    "y = df['subject'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3b33c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.71819137e-02,  5.40516740e-02,  2.50176036e-02,  1.14518850e-01,\n",
       "       -7.85411522e-02,  1.30640935e-02,  3.58285419e-02, -6.75797112e-02,\n",
       "        7.36248103e-02,  6.86810596e-02, -4.54513636e-02, -7.67141224e-02,\n",
       "       -6.77699288e-02,  2.73177799e-02, -7.98190704e-02,  7.59754935e-02,\n",
       "        4.45443708e-02,  8.43538618e-02, -1.47920167e-02, -1.06285138e-01,\n",
       "        6.77503435e-03,  1.85826188e-02,  7.43438349e-02, -3.25057897e-02,\n",
       "        2.55168333e-02,  1.56954695e-02, -6.63747464e-02,  5.96237614e-02,\n",
       "        6.17961129e-02, -1.28616290e-02,  5.54932848e-03,  1.14513009e-02,\n",
       "       -5.35750739e-02, -1.06623590e-02,  1.70911369e-02,  4.06849317e-03,\n",
       "        1.69035270e-02,  2.94505620e-02,  3.38409769e-02,  6.55624584e-02,\n",
       "        9.58070189e-02, -6.69507388e-02,  1.19275282e-01,  4.10365735e-02,\n",
       "       -2.09394983e-02, -1.01718666e-01, -1.83075296e-03,  9.23812996e-03,\n",
       "       -3.12465517e-02,  2.57248097e-02, -7.30874013e-02,  4.00103499e-02,\n",
       "       -7.04093976e-03,  7.74840447e-03,  1.39113496e-02,  3.73275455e-02,\n",
       "       -9.28639988e-02, -7.41888480e-02,  4.21406159e-02, -9.44235419e-02,\n",
       "       -4.31763385e-03,  6.02794367e-02, -6.44919832e-02, -1.56703453e-02,\n",
       "        2.82140182e-02, -4.03554453e-02, -6.47668354e-02,  4.28365503e-02,\n",
       "       -1.76445050e-02,  8.22543559e-02,  6.33017488e-02,  6.35870810e-02,\n",
       "        5.05058388e-02,  4.50682559e-02, -1.12937539e-01, -4.43678172e-02,\n",
       "        3.77830031e-02,  7.41039211e-02,  5.57321667e-02,  1.11592524e-01,\n",
       "       -1.74487809e-02, -1.95193749e-02, -1.34930368e-03, -1.61337987e-02,\n",
       "       -1.47980943e-02, -1.17978457e-02, -9.16994601e-02,  1.10683247e-01,\n",
       "        1.55735144e-02,  3.25412211e-02,  3.59313448e-02,  2.72685606e-02,\n",
       "       -1.05365451e-01, -7.45801333e-02, -1.09402500e-02, -1.93728862e-02,\n",
       "        2.86201865e-02,  6.46577824e-02,  5.75330379e-02, -2.61378746e-02,\n",
       "       -4.91732150e-02, -2.87046271e-03,  3.44246040e-02, -8.86654180e-03,\n",
       "       -3.52709064e-02, -5.41624727e-02, -4.24815463e-02, -4.05891224e-02,\n",
       "        3.35096801e-02, -5.23802332e-02, -9.28025434e-02, -3.64021689e-02,\n",
       "       -1.01291204e-02,  3.12909661e-02,  1.21192113e-01, -1.59598313e-02,\n",
       "        5.36686957e-03, -7.66024832e-02,  3.77899105e-02,  2.73357354e-02,\n",
       "       -1.21199505e-02, -1.39942924e-02, -6.98552751e-02,  5.25679939e-02,\n",
       "        4.29961318e-02, -7.21991372e-02, -1.18760362e-02, -1.91409009e-02,\n",
       "        1.85473167e-02, -3.04543878e-02, -8.49473167e-02, -6.56265862e-02,\n",
       "       -1.62445866e-02,  3.15218996e-02, -4.13508011e-02, -8.39229088e-03,\n",
       "       -3.10036719e-02,  2.03136724e-02,  3.47007924e-02,  5.76807227e-02,\n",
       "        6.86598093e-02, -6.73102255e-02, -5.73700296e-03,  5.14156536e-03,\n",
       "        1.36888148e-02,  8.39685990e-03, -2.54648500e-02, -8.07691671e-02,\n",
       "       -5.36536935e-04, -8.99524581e-02,  9.76891814e-02, -1.11308125e-02,\n",
       "       -6.37833762e-02,  4.02066290e-02, -2.98085617e-02, -3.52135351e-02,\n",
       "       -4.74997483e-02, -5.74959793e-02, -5.54527240e-02, -5.73615812e-02,\n",
       "       -2.74030610e-02,  3.99536305e-02,  2.81583711e-02, -1.88058972e-02,\n",
       "        3.39095121e-02, -1.03857008e-01,  6.78185932e-02, -7.93086338e-02,\n",
       "       -2.15206470e-02,  2.10551461e-02, -8.60108844e-02, -1.12873659e-02,\n",
       "       -2.20976576e-02, -8.06123981e-02,  6.69940582e-03,  3.25244968e-02,\n",
       "        1.00297960e-01, -5.91314923e-02,  4.20573606e-03, -1.38656702e-02,\n",
       "       -7.85496168e-02, -7.49703962e-02,  2.33398265e-02, -1.85321873e-02,\n",
       "       -4.27884032e-03, -1.21500802e-02, -4.07552773e-02, -3.89659472e-05,\n",
       "        4.14824405e-02,  1.37707554e-02,  6.29598327e-02,  4.06529055e-02,\n",
       "       -1.68966089e-02, -1.30178161e-03,  2.60819688e-02,  5.79875364e-02,\n",
       "       -1.82387896e-02, -1.26137599e-02, -6.46138164e-02, -5.65844175e-02,\n",
       "       -6.33589750e-02,  8.12724377e-02, -7.25508006e-03, -3.66228395e-02,\n",
       "       -2.67844335e-02, -4.16403733e-02, -1.04427876e-02,  9.49863930e-03,\n",
       "       -3.93066406e-02,  2.26692157e-03,  1.55021107e-02,  6.25946670e-02,\n",
       "       -2.66591735e-02, -5.03768490e-03, -1.02075264e-01,  1.01611735e-02,\n",
       "        7.60527789e-02, -6.35995164e-02, -1.03895802e-01,  1.67799265e-02,\n",
       "       -5.37914556e-02,  2.13537701e-02, -5.28183630e-03,  5.68439462e-03,\n",
       "        5.68520066e-02, -5.26116366e-02,  5.81749954e-02,  1.34255792e-02,\n",
       "       -5.32898122e-03, -3.23357016e-02,  1.12674950e-02,  1.05349438e-02,\n",
       "       -2.66336129e-02,  4.23988299e-02,  6.04962710e-02,  2.11401040e-02,\n",
       "        1.62076223e-02, -5.39138492e-02,  8.03850680e-02,  3.75817509e-02,\n",
       "        8.06808148e-02,  2.15981478e-02, -3.48796952e-03, -2.77323534e-02,\n",
       "       -5.29918778e-02,  3.40139960e-02, -2.45239991e-02,  6.85737739e-02,\n",
       "       -3.93366410e-03, -5.94460439e-02,  2.17576539e-02,  7.54210942e-02,\n",
       "        4.34788418e-02,  9.64374003e-02,  6.44421766e-02, -5.92343821e-03,\n",
       "       -1.78749427e-02,  4.37892763e-02, -3.72297643e-02, -5.92920767e-02,\n",
       "        2.83756579e-02,  1.46986536e-02, -5.81051239e-02,  1.06083067e-03,\n",
       "        4.00015621e-02,  7.29084338e-02, -5.62143272e-02,  1.10686135e-02,\n",
       "       -5.99129887e-02, -2.07339357e-02,  8.01482982e-03,  3.89673265e-02,\n",
       "        1.07376142e-01, -3.99820791e-02,  3.06127516e-02, -7.48927230e-02,\n",
       "       -6.27861238e-02, -8.27278094e-02, -4.27697823e-02,  4.81996267e-02,\n",
       "        7.31768851e-03,  2.41776806e-02,  1.28501418e-03,  6.43263833e-02,\n",
       "        6.39782922e-03, -2.34680176e-02, -8.53452952e-02,  3.04056803e-02,\n",
       "        4.84141549e-02,  1.91441768e-03,  5.73332620e-02,  7.28223553e-02,\n",
       "       -8.62970298e-02, -2.37216626e-02, -4.53291209e-02, -1.06424967e-01,\n",
       "       -8.08853214e-03, -4.45675661e-02, -1.05190816e-02,  1.68396686e-02])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a138631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5704c87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43125 entries, 0 to 43124\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   subject  43125 non-null  int64 \n",
      " 1   vec      43125 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 674.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9a9c38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a709505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roronoa/.conda/envs/tf/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13238390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7066666666666667\n",
      "0.6766619852135636\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "predicted = classifier.predict(X_test)\n",
    "f1 = f1_score(y_test, predicted, average = 'weighted')\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33a1b854",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4716/4068691315.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Make predictions on the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_counters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m         \u001b[0mcheck_non_negative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MultinomialNB (input X)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_non_negative\u001b[0;34m(X, whom)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX_min\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Negative values in data passed to %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mwhom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = mnb.predict(X_test)\n",
    "\n",
    "# Calculate weighted F1 score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the classification report, including precision, recall, and F1 score for each class\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Weighted F1 Score:\",f1)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c158e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43125 entries, 0 to 43124\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   subject  43125 non-null  int64 \n",
      " 1   vec      43125 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 674.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cb7bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
