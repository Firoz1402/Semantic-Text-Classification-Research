{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "564f5384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 00:39:58.055149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 00:39:58.751803: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roronoa/.conda/envs/tf/lib/python3.7/site-packages/nvidia/cudnn/lib:/home/roronoa/.conda/envs/tf/lib/:\n",
      "2023-10-20 00:39:58.751888: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roronoa/.conda/envs/tf/lib/python3.7/site-packages/nvidia/cudnn/lib:/home/roronoa/.conda/envs/tf/lib/:\n",
      "2023-10-20 00:39:58.751898: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.utils import resample\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.layers import Embedding, Bidirectional, SimpleRNN, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "864492fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/CleanedEcommerce.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ac7a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8540cfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'desc'\n",
    "label = 'label'\n",
    "num_classes = df[label].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67627284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ddbb1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df[label] = label_encoder.fit_transform(df[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4fb4624",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[text]\n",
    "y = df[label]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify =y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e3646b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000  # Maximum number of words to keep in the vocabulary\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1033583",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "max_sequence_length = 300  # You can adjust this to your desired sequence length\n",
    "X_train = pad_sequences(X_train, maxlen=max_sequence_length)\n",
    "X_test = pad_sequences(X_test, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21b236d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22240,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4565828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=32, input_length=max_sequence_length))\n",
    "model.add(Bidirectional(SimpleRNN(16, return_sequences=True)))  # Bidirectional SimpleRNN layer\n",
    "model.add(Bidirectional(SimpleRNN(16, return_sequences=True)))  # Bidirectional SimpleRNN layer\n",
    "model.add(SimpleRNN(16))  # SimpleRNN layer\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer='l2'))  # L2 regularization\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.04, patience=10, mode='max', restore_best_weights=True)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fec17743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "70/70 [==============================] - 38s 511ms/step - loss: 1.4156 - accuracy: 0.4440 - val_loss: 0.9729 - val_accuracy: 0.7010\n",
      "Epoch 2/30\n",
      "70/70 [==============================] - 35s 501ms/step - loss: 0.8705 - accuracy: 0.7232 - val_loss: 0.7259 - val_accuracy: 0.7556\n",
      "Epoch 3/30\n",
      "70/70 [==============================] - 35s 504ms/step - loss: 0.6888 - accuracy: 0.7973 - val_loss: 0.5893 - val_accuracy: 0.8476\n",
      "Epoch 4/30\n",
      "70/70 [==============================] - 35s 504ms/step - loss: 0.5535 - accuracy: 0.8768 - val_loss: 0.4791 - val_accuracy: 0.8898\n",
      "Epoch 5/30\n",
      "70/70 [==============================] - 35s 498ms/step - loss: 0.4805 - accuracy: 0.8987 - val_loss: 0.4381 - val_accuracy: 0.8984\n",
      "Epoch 6/30\n",
      "70/70 [==============================] - 34s 485ms/step - loss: 0.4040 - accuracy: 0.9206 - val_loss: 0.4140 - val_accuracy: 0.8988\n",
      "Epoch 7/30\n",
      "70/70 [==============================] - 34s 483ms/step - loss: 0.3560 - accuracy: 0.9323 - val_loss: 0.3980 - val_accuracy: 0.9047\n",
      "Epoch 8/30\n",
      "70/70 [==============================] - 34s 489ms/step - loss: 0.3471 - accuracy: 0.9317 - val_loss: 0.4374 - val_accuracy: 0.8925\n",
      "Epoch 9/30\n",
      "70/70 [==============================] - 34s 480ms/step - loss: 0.3065 - accuracy: 0.9436 - val_loss: 0.3854 - val_accuracy: 0.9065\n",
      "Epoch 10/30\n",
      "70/70 [==============================] - 34s 492ms/step - loss: 0.2729 - accuracy: 0.9500 - val_loss: 0.3807 - val_accuracy: 0.9078\n",
      "Epoch 11/30\n",
      "70/70 [==============================] - 34s 492ms/step - loss: 0.2530 - accuracy: 0.9555 - val_loss: 0.3918 - val_accuracy: 0.9087\n",
      "Epoch 12/30\n",
      "70/70 [==============================] - 35s 502ms/step - loss: 0.2648 - accuracy: 0.9500 - val_loss: 0.4652 - val_accuracy: 0.8781\n",
      "Epoch 13/30\n",
      "70/70 [==============================] - 35s 503ms/step - loss: 0.2864 - accuracy: 0.9403 - val_loss: 0.3988 - val_accuracy: 0.9015\n",
      "Epoch 14/30\n",
      "70/70 [==============================] - 34s 490ms/step - loss: 0.2388 - accuracy: 0.9542 - val_loss: 0.4168 - val_accuracy: 0.9018\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, batch_size=256, validation_split=0.2,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9b3677f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 12s 66ms/step\n",
      "Weighted F1 Score: 0.8888784497718066\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91      1251\n",
      "           1       0.81      0.95      0.87      1135\n",
      "           2       0.90      0.78      0.83      1062\n",
      "           3       0.91      0.92      0.92      2113\n",
      "\n",
      "    accuracy                           0.89      5561\n",
      "   macro avg       0.89      0.88      0.88      5561\n",
      "weighted avg       0.89      0.89      0.89      5561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_probabilities = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Weighted F1 Score: {f1}')\n",
    "print(\"Classification Report :\\n\",classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a2f498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
